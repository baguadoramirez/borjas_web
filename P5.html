<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Práctica 5: Percepción de expresiones emocionales</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<html>
<link rel="shortcut icon" href="./images/favicon.png">
</html>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 64px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h2 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h3 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h4 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h5 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h6 {
  padding-top: 69px;
  margin-top: -69px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Borja's personal web page</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="CV.html">Curriculum Vitae</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Percepcion y Atencion
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Practica 1</li>
    <li>
      <a href="P1.html">Efectos cromaticos</a>
    </li>
    <li class="dropdown-header">Práctica 2: Psicofísica clásica</li>
    <li>
      <a href="P2_A.html">Introducción</a>
    </li>
    <li>
      <a href="P2_B.html">Obtención del umbral de detección de la colinealidad</a>
    </li>
    <li>
      <a href="P2_C.html">Detección del Umbral de discriminación (Umbral diferencial) de la Colinealidad</a>
    </li>
    <li class="dropdown-header">Practica 3</li>
    <li>
      <a href="P3.html">Estimación de la Claridad (psicofísica de Stevens)</a>
    </li>
    <li class="dropdown-header">Practica 4</li>
    <li>
      <a href="P4.html">Precedencia perceptiva (Global-to-Local)</a>
    </li>
    <li class="dropdown-header">Practica 5</li>
    <li>
      <a href="P5.html">Percepción de expresiones emocionales</a>
    </li>
    <li class="dropdown-header">Demos</li>
    <li>
      <a href="demos.html">Demos &amp; Psychopy code</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Práctica 5: Percepción de expresiones emocionales</h1>

</div>


<div id="indice-de-objetivos" class="section level1">
<h1>Índice de objetivos</h1>
<ul>
<li><p>Comprobar si existen diferencias interhemisféricas (asimetrías cerebrales) en el procesamiento de emociones.</p></li>
<li><p>Introducir la técnica de campo visual dividido.</p></li>
<li><p>Intentar replicar el estudio de Alves, Aznar-Casanova &amp; Fukusima (2008) con rostros esquemáticos.</p></li>
</ul>
</div>
<div id="introduccion" class="section level1">
<h1>Introducción</h1>
<p>Durante el transcurso de estas clases, ya hemos visto cómo el ser humano es capaz de acceder a diferente rasgos o características que definen un estímulo de manera bastante eficiente. Aunque hasta ahora nos hemos centrado en elementos como podrían ser la luminancia, contraste, co-colinealidad, o patrones sencillos como son letras, el procesamiento de estímulos visuales tan complejos como las expresiones emocionales es importante para estudiar nuestra interacción diaria.</p>
<p>Las expresiones emocionales son patrones estimulares complejos. Concretamente, identificar las expresiones emocionales de rostros son determinantes para nuestra supervivencia en sociedad. Continuamente nos encontramos realizando inferencias sobre los rasgos presentes en tales rostros y modificnado nuestra conducta para poder adaptarnos a la situación. por ejemplo….</p>
<figure>
<p>
<img src="pia/P5/ruby_rose.jpg" width="350px">
<figcaption>
¿Hombre, Mujer, Intersexual? ¿Edad? ¿Inteligente? ¿Atractivx? ¿Conocidx? ¿Se trata de una persona hostil? ¿Qué emoción está sientiendo?
</figcaption>
</figure>
<p>Desde el punto de vista de la congnición social, se ha estudiado cómo tanto seres humanos como primates identifican las expresiones faciales de los otros. Según <a href="https://doi.org/10.1080/02699939208411068">Ekman (1992); pág. 171</a>, la función primaria de las emociones propias sería la de movilizar a un organismo a realizar ciertas acciones para conseguir un objetivo dentro de su vida social. En su estudio de las emociones, Ekman propuso que había una serie de emociones básicas compartidas entre todas las civilizaciones humanas: ira, miedo, asco, sorpresa, alegría y tristeza. Dado que diferentes emociones dan lugar a diferentes probablidades de que se manifieste una conducta posterior, ser capaz de identificar de forma rápida la expresión facial de una persona potencialmente hostil (se sabe que se produce alrededor de los 100ms.) sería de gran utilidad adaptativa.</p>
<figure>
<p>
<img src="pia/P5/Faces.png" width="350px">
<figcaption>
Si veo al monete de la tercera imagen acercándose a mí, yo empezaría a correr lo más pronto posible.
</figcaption>
</figure>
<p>Pero, ¿por qué es importante esto dentro de la sub-asignatura de “Percepción Visual”? <a href="10.1037//0022-3514.53.1.53">Forgas y Bower (1987)</a> estudiaron el efecto que tienen las emociones dentro del procesamiento cognitivo. Al hacer esto encontraron que cuando cambiaba el componente emocional de un observador, cambiaban factores cognitivos de respuesta (criterio de decisión) a experimentos psicofísicos, sin embargo, no pudieron encontrar diferencias en el componente sensorial (detectabilidad o discriminabilidad). Es decir, que aunque sensorialmente funcionaban igual de bien (eran igual de buenos en detectar o de discriminar estímulos), sus respuestas eran moduladas por la emoción sentida o identificada en otros.</p>
<p>Actualmente podemos decir que existen dos perspectivas distintas en cuanto a cuáles son las bases neurales del procesamiento de las emociones:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Hipótesis del hemisferio derercho</strong> podemos encontrar un claro ejemplo de esta teoría en <a href="http://dx.doi.org/10.1037/0894-4105.12.3.446">Borod, 1998</a>: Según esta teoría, todas las emociones serán procesadas más fácilmente por el hemisferio derecho independientemente de su valencia.</p></li>
<li><p><strong>Hipótesis del acercamiento-retraimiento</strong> de <a href="https://doi.org/10.1111/1469-8986.00067">Davidson (2003)</a>: Según esta teoría el hemisferio iquierdo procesaría las emociones positivas mientras que el hemisferio derecho procesaría de forma principal las emociones negativas.</p></li>
</ol>
<p>Desde el punto de vista funcional, <a href="https://scholar.google.es/scholar?cluster=1079682260296463766&amp;hl=es&amp;as_sdt=2005&amp;sciodt=0,5">Davidson (1995)</a> propuso una división del sistema emocional en tres subsistemas o componentes:</p>
<!--  
<figure>
<p><img src="pia/P5/Sistema_limbico.png" width="350px">
<figcaption> 
</figcaption>
</figure>
-->
<ol style="list-style-type: decimal">
<li><strong>Experiencia emocional (experiencia externa/interna que genera la emoción)</strong></li>
</ol>
<figure>
<p>
<img src="pia/P5/Experiencia.png" width="350px">
<figcaption>
</figcaption>
</figure>
<ol start="2" style="list-style-type: decimal">
<li><strong>Expresión emocional (factor conductual en el sentido más amplio de la palabra)</strong></li>
</ol>
<figure>
<p>
<img src="pia/P5/Expresion.gif" width="350px">
<figcaption>
</figcaption>
</figure>
<ol start="3" style="list-style-type: decimal">
<li><strong>Percepción emocional (identificación de la propia emoción, metacognición de la emoción)</strong></li>
</ol>
<figure>
<p>
<img src="pia/P5/Percepcion.png" width="350px">
<figcaption>
</figcaption>
</figure>
<hr />
<p><strong>Para reflexionar:</strong> ¿Es siempre directamente accesible la percepción emocional? No. Por ejemplo, cuando nos sentimos molestos por tener hambre. A todos nos habrá ocurrido que en caso de hambre nos sentimos molestos, sin embargo, no somos conscientes de por qué nos sentimos así. Esto hace que atrubyamos nuestra molestia a cualquier evento/persona externa.</p>
<hr />
<p>En esta práctica se pretende mostrar que la identificación de la emoción de un tercero es beneficiosa en tanto que ayuda a la planificación de la acción. Es importante entender que para que se pueda identificar una emoción, primero han de ser percibidos los rasgos faciales que indican esa emoción. Bajo las teorías anteriormente mencionadas (p.e. HD y acercamiento-retraimiento) el procesamiento de la expresión facila por un hemisferio u otro afectará a su velocidad de procesamiento. Es aquí donde entra en juego la <strong>técnica de campo visual dividido</strong>.</p>
<p><strong>¿En qué consiste ésta técnica?</strong> Cuando miramos hacia un elemento en el entorno, la luz proviniente del campo visual derecho se refleja en la parte izquierda de la retina. Esta información a su vez es procesada por el hemisferio izquierdo y viceversa. De esta manera, podemos aprovechar esta asimetría en el sistema visual para controlar qué información se está procesando por cada hemisferio cerebral. De esta manera, podemos estudiar si existe una asimetría en el procesamiento de expresiones faciales emocionales.</p>
<figure>
<p>
<img src="pia/P5/Campos_Visuales.png" width="350px">
<figcaption>
El campo visual derecho se refleja en la hemiretina izquierda haciendo que se procese por el hemisferio izquierdo. El campo visual izquierdo se refleja en la hemiretina derecha haciendo que se procese principalmente por el hemisferio derecho. NOTA: Es importante indicar que hay parte del espacio visual que sólo se refleja en una de las hemiretinas y por lo tanto sólo es porcesada por un hemisferio como los espacios visuales laterales inferiores.
</figcaption>
</figure>
<div id="estudio-de-alves-n.-t.-fukusima-s.-s.-aznar-casanova-j.-a.-2008" class="section level2">
<h2>Estudio de Alves, N. T., Fukusima, S. S., &amp; Aznar-Casanova, J. A. (2008)</h2>
<p>Utilizando la técnica de campo visual dividido <a href="http://dx.doi.org/10.3922/j.psns.2008.1.010">Alves, N. T., Fukusima, S. S., &amp; Aznar-Casanova, J. A. (2008)</a> mostraron a diferentes observadores una serie de imágenes mostrando rostros con expresiones emocionales a ambos lados de una pantalla. De esta manera, las expresiones emocionales eran procesadas por el hemisferio izquierdo o derecho dependiendo de en qué lado de la pantalla eran mostradas. En este experimento, los autores se preguntaron si es posible que un hemisferio que procese más rápidamente/eficazmente cada una de las emociones mostradas.</p>
<p>Para ello mostraron a 80 participantes distribuidos en 5 grupos experimentales imágenes de caras con expresiones de felicidad o sorpresa (categorizadas como estímulos positivos), caras enfadadas o tristes (categorizadas como estímulos negativos) o caras con expresión neutra (estímulos no-emocionales).</p>
<ul>
<li><p>Grupo 1 = target Felicidad (vs T, S, N, M)</p></li>
<li><p>Grupo 2 = target Miedo (vs T, N, S, F)</p></li>
<li><p>Grupo 3 = target Neutral (vs T, M, S, F)</p></li>
<li><p>Grupo 4 = target Sorpresa (vs F, N, T, M)</p></li>
<li><p>Grupo 5 = target Tristeza (vs F, N, M, S)</p></li>
</ul>
<p>Los participantes tenían que indicar el lado de la pantalla en la que se mostraba la emoción correspondiente al grupo al que se le había asignado. Es decir, si el participante pertenecía al primer grupo (target: alegría), debería buscar el rostro que muestra la emoción de alegría y seleccionar en qué lado de la pantalla se había mostrado. En la siguiente figura se muestran dos ensayos diferentes en los que debería seleccionar izquierda para el primero y derecha en el segundo ensayo.</p>
<figure>
<p>
<img src="pia/P5/Trials_2008.png" width="350px">
<figcaption>
</figcaption>
</figure>
<p>Los resultados en este experimento fueron los siguientes:</p>
<figure>
<p>
<img src="pia/P5/Resultados_2008.png" width="350px">
<figcaption>
Recuerda… Campo visual izquierdo -&gt; Hemiretina derecha -&gt; Hemisferio derecho
</figcaption>
</figure>
<p>Sin embargo, los resultados obtenidos no dieron soporte completo a ninguna de las dos teorías, sino que dan soporte parcial a ambas propuestas. Aunque los resultados con rostros neutros sugieren mayor apoyo empírico a la hipótesis del HD.</p>
<hr />
<p><strong>Para pensar:</strong> ¿Por qué el hecho de que los resultados de los rostros neutros muestren diferencias significativas aportan soporte parcial a la hipótesis del HD? <!--In other words, their better performance for perceiving neutral expressions in the right visual field might be a result of the right hemisphere’s advantage for perceiving emotions in the left visual field, irrespectively of their category (hapiness, fear, surprise and sadness). en otras palabras, su mejor performance para percibir estñimulos neutros en el hemiretina derecha (hemisferio izquierdo) podría se el resultado de la ventaja del hemisferio derecho para percibir emociones independientemente de su categoría.--></p>
<hr />
<p>Los autores proponen que se profundice en la naturaleza de los estímulos (por ejem., estáticos / dinámicos), ya que el patrón de resultados da lugar a interpretaciones.</p>
</div>
</div>
<div id="P5" class="section level1">
<h1>Práctica 5: Percepción de expresiones emocionales</h1>
<p><strong>Pregunta experimental:</strong> Dados los resultados del experimento anterior, los autores propusieron que sería interesante replicar los resultados con estímulos de otra naturaleza. Para ello, en este caso realizaremos un experimento con caricaturas que reflejan diferentes expresiones emocionales de una manera esquemática.</p>
<p><strong>Para realizar el experimento, tendréis que descargar el ejecutable que se encuentra en el campus virtual: Práctica 5 Percepción de expresiones emocionales</strong></p>
<p><strong>Hipótesis: </strong> No tenemos una dirección de hipótesis fija. Se trata de un estudio exploratorio para ver si los datos arrojan soporte a la hipótesis del acercamiento-retraimiento o a la hipótesis del hemisferio derecho.</p>
<div id="metodologia" class="section level2">
<h2>Metodología</h2>
<p><strong>Estímulos:</strong> Se utilizarán caricaturas mostrando con las siguientes expresiones emocionales: Neutral, Felicidad, Tristeza, Miedo y Sorpresa.</p>
<figure>
<p>
<img src="pia/P5/P5.png" width="350px">
<figcaption>
</figcaption>
</figure>
<p><strong>Instrucciones:</strong> El método será parecido al del experimento anterior. En concreto, tenéis 3 ejecutables distintos en los que tendréis que atender y buscar expresiones de “Felicidad”, “Tristeza” o “Neutras” dependiendo del ejecutable en el que os encontréis.</p>
<ul>
<li><p>Grupo 1 = target Felicidad (vs T, N, M)</p></li>
<li><p>Grupo 2 = target Tristeza (vs N, S, F)</p></li>
<li><p>Grupo 3 = target Neutra (vs T, M, S, F)</p></li>
</ul>
<p>La tarea es la siguiente: si nos encontramos en el grupo 1 (Felicidad), tendremos que indicar en qué lado de la pantalla se encuentra la caricatura que muestra esa emoción con el mouse.</p>
<figure>
<p>
<img src="pia/P5/Trials_P5.png" width="350px">
<figcaption>
</figcaption>
</figure>
<p><strong>Variables</strong></p>
<ul>
<li><p>Variables independientes (VI):</p>
<ul>
<li><p>Grupo asignado.</p></li>
<li><p>Emoción distractora.</p></li>
<li><p>Posición de la emoción target.</p></li>
</ul></li>
<li><p>Variable dependiente (VD), aquella que manipula el observador:</p>
<ul>
<li><p>Tiempo de reaccción.</p></li>
<li><p>Tasa de errores.</p></li>
</ul></li>
</ul>
</div>
<div id="resultados" class="section level2">
<h2>Resultados</h2>
<p>Los resultados obtenidos “en general” serán los siguientes:</p>
<ul>
<li><p>Si observamos los RTs:</p>
<ul>
<li><p>Los estímulos positivos se procesan más rápido por el hemisferio izquierdo.</p></li>
<li><p>Los estímulos negativos parecen no mostrar diferencias significativas entre hemisferios.</p></li>
<li><p>En el procesamiento de los estimulos neutros no hay diferencias.</p></li>
</ul></li>
</ul>
<figure>
<p>
<img src="pia/P5/Resultados_TR_P5.png" width="350px">
<figcaption>
</figcaption>
</figure>
<ul>
<li><p>Si observamos el % de errores:</p>
<ul>
<li><p>En los estímulos positivos hay menos errores cuando son procesados por el hemisferio izquierdo.</p></li>
<li><p>Los estimulos negativos procesados por el hemisferio derecho dan lugar a menor tasa de errores.</p></li>
</ul></li>
</ul>
<figure>
<p>
<img src="pia/P5/Resultados_errores_P5.png" width="350px">
<figcaption>
</figcaption>
</figure>
</div>
<div id="discusion" class="section level2">
<h2>Discusión</h2>
<p>Los resultados con caricaturas muestran una tendencia que parece encajar con la hipótesis de acercamiento-retraimiento. Por su parte, los resultados del experimento de Alves, Aznar-Casanova y Fukusima (2008) parecerían dar soporte parcial a la hipótesis del HD.</p>
<hr />
<p><strong>Para pensar más:</strong></p>
<ul>
<li><p>¿Por qué puede ocurrir esto?</p></li>
<li><p>¿Se te ocurre algún otro experimento que pudiera ser interesante de realizar utilizando la técnica de Campo Visual Dividido?</p></li>
<li><p>¿Hay alguna zona del campo visual que sólo sea procesada por un hemisferio?</p></li>
</ul>
<p><br></p>
</div>
</div>

<html>
<footer role="contentinfo" id="site-footer">
<small><p class="copyright">&#169; 2019,
		This webpage was created by Borja Aguado using <a href="http://www.r-project.org">R</a> with <a href="http://rmarkdown.rstudio.com">RMarkdown</a>, hosted on <a href="http://github.com">Github</a> and based on <a href="https://github.com/jules32/rmarkdown-website-tutorial"> jules32/rmarkdown-website-tutorial</a> project. </small></p>
</footer>
</html>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
